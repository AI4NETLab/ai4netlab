@inproceedings{DR:ICDM-20,
  author = {Andrian Putina and Mauro Sozio and Jose M. Navarro and Dario Rossi},
  title = {Random Histogram Forest for Unsupervised Anomaly Detection},
  booktitle = {20th IEEE International Conference on Data Mining (ICDM)},
  month = {Nov.},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {Roughly speaking, anomaly detection consists of identifying instances whose features significantly deviate from the rest of input data. It is one of the most widely studied problems in unsupervised machine learning, boasting applications in network intrusion detection, fraud detection, healthcare and many others. Several methods have been developed in recent years, however, a satisfactory solution is still missing to the best of our knowledge. We present Random Histogram Forest an effective approach for unsupervised anomaly detection. Our approach is probabilistic, which has been proved to be effective in identifying anomalies. Moreover, it employs the fourth central moment (aka kurtosis), so as to identify potential anomalous instances. We conduct an extensive experimental evaluation on 38 datasets including all benchmarks for anomaly detection, as well as the most successful algorithms for unsupervised anomaly detection, to the best of our knowledge. Moreover, we provide some novel datasets that are made publicly available. We evaluate all the approaches in terms of the average precision of the area under the precision-recall curve (AP) as well as ROC. Our evaluation shows that our approach significantly outperforms all other approaches, both in terms of both AP and ROC, while boasting linear running time.},
  doi = {},
  howpublished = { https://ieeexplore.ieee.org/document/9338384},
  topic = {ad-algo},
}

@inproceedings{DR:CNSM-20a,
  author = {Sarah Wassermann and Pedro Casas and Zied Ben Houidi and Alexis Huet and Michael Seufert and Nikolas Wehner and Joshua Schuler and Sheng-Ming Cai and Hao Shi and Jinchun Xu and Tobias Hossfeld and Dario Rossi},
  title = {Are you on Mobile or Desktop? On the Impact of End-User Device on Web QoE Inference from Encrypted Traffic},
  booktitle = {IEEE International Conference on Network and Service Management (CNSM)},
  month = {Nov.},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {Web browsing is one of the key applications of the Internet, if not the most important one. We address the problem of Web Quality-of-Experience (QoE) monitoring from the ISP perspective, relying on in-network, passive measurements. As a proxy to Web QoE, we focus on the analysis of the well-known SpeedIndex (SI) metric. Given the lack of application-level-data visibility introduced by the wide adoption of end-to-end encryption, we resort to machine-learning models to infer the SI and the QoE level of individual web-page loading sessions, using as input only packet- and flow-level data. In this paper, we study the impact of different end-user device types (e.g., smartphone, desktop, tablet) on the performance of such models. Empirical evaluations on a large, multi-device, heterogeneous corpus of Web-QoE measurements for the most popular websites demonstrate that the proposed solution can infer the SI as well as estimate QoE ranges with high accuracy, using either packet-level or flow-level measurements. In addition, we show that the device type adds a strong bias to the feasibility of these Web-QoE models, putting into question the applicability of previously conceived approaches on single-device measurements. To improve the state of the art, we conceive cross-device generalizable models operating at both packet and flow levels, offering a feasible solution for Web-QoE monitoring in operational, multi-device networks. To the best of our knowledge, this is the first study tackling the analysis of Web QoE from encrypted network traffic in multi-device scenarios.},
  doi = {},
  howpublished = {https://ieeexplore.ieee.org/document/9269127},
  topic = {web-qoe},
}

@inproceedings{DR:CNSM-20b,
  author = {Alexis Huet and Zied Ben Houidi and Bertrand Mathieu and Dario Rossi},
  title = {Detecting Degradation of Web Browsing Quality of Experience (QoE)},
  booktitle = {IEEE International Conference on Network and Service Management (CNSM)},
  month = {Nov.},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {Quality of Experience (QoE) inference, and particularly the detection of its degradation is an important management tool for ISPs. Yet, this task is made difficult due to widespread use of encryption on the data-plane on the one hand so that measuring QoE is hard, and to the ephemeral properties of the web content on the other hand so that changes in QoE indicators may be rooted in changes in properties of the content itself, more than being caused by network-related events. In this paper, we phrase the QoE degradation detection issue as a change point detection problem, that we tackle by leveraging a unique dataset consisting on several hundreds thousands browsing sessions spanning multiple months. Our results, beyond showing feasibility, warn about the exclusive use of QoE indicators that are very close to content, as changes in the content space can lead to false alarms that are not tied to network-related problems.},
  doi = {},
  howpublished = {https://nonsns.github.io/paper/rossi20cnsm-b.pdf},
  topic = {web-qoe},
}

@article{DR:TNSM-20b,
  author = {Andrian Putina and Dario Rossi},
  journal = {IEEE Transactions on Network and Service Management},
  title = {Online anomaly detection leveraging stream-based clustering and real-time telemetry},
  year = {2020},
  month = {November},
  volume = {18},
  number = {1},
  abstract = {Recent technology evolution allows network equipment to continuously stream a wealth of “telemetry” information, which pertains to multiple protocols and layers of the stack, at a very fine spatial-grain and high-frequency. This deluge of telemetry data clearly offers new opportunities for network control and troubleshooting, but also poses a serious challenge for what concerns its real-time processing. We tackle this challenge by applying streaming machine-learning techniques to the continuous flow of control and data-plane telemetry data, with the purpose of real-time detection of anomalies. In particular, we implement an anomaly detection engine that leverages DenStream, an unsupervised clustering technique, and apply it to features collected from a large-scale testbed comprising tens of routers traversed up to 3 Terabit/s worth of real application traffic. We contrast DenStream with offline algorithms such as DBScan and Local Outlier Factor (LOF), as well as online algorithms such as the windowed version of DBScan, ExactSTORM, Continuous Outlier Detection (COD) and Robust Random Cut Forest (RRCF). Our experimental campaign compares these seven algorithms under both accuracy and computational complexity viewpoints: results testify that DenStream (i) achieves detection results on par with RRCF, the best performing algorithm and (ii) is significantly faster than other approaches, notably over two orders of magnitude faster than RRCF. In spirit with the recent trend toward reproducibility of results, we make our code available as open source to the scientific community.},
  pages = {--},
  doi = {110.1109/TNSM.2020.3037019},
  howpublished = {https://ieeexplore.ieee.org/document/9253727},
  topic = {ad-algo},
}

@misc{DR:PATENT-PCT/EP2020/080037,
  author = {James Roberts and Dario Rossi},
  title = {Method Of Managing Data Transmission For Ensuring Per-Flow Fair Bandwidth Sharing},
  month = {October},
  year = {2020},
  howpublished = {},
}

@misc{DR:PATENT-PCT/EP2020/077766,
  author = {Alexis Huet, Dario Rossi},
  title = {Detecting A Network-Induced Contribution To A Quality Of Experience Degradation},
  month = {October},
  year = {2020},
  howpublished = {},
}

@inproceeding{DR:ITC-20,
  author = {Jose M. Navarro and Dario Rossi},
  title = {HURRA! Human readable router anomaly detection},
  booktitle = {International Teletraffic Congress (ITC32)},
  month = {Sep.},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {This paper presents HURRA, a system that aims to reduce the time spent by human operators in the process of network troubleshooting. To do so, it comprises two modules that are plugged after any anomaly detection algorithm: (i) a first attention mechanism, that ranks the present features in terms of their relation with the anomaly and (ii) a second module able to incorporates previous expert knowledge seamlessly, without any need of human interaction nor decisions. We show the efficacy of these simple processes on a collection of real router datasets obtained from tens of ISPs which exhibit a rich variety of anomalies and very heterogeneous set of KPIs, on which we gather manually annotated ground truth by the operator solving the troubleshooting ticket. Our experimental evaluation shows that (i) the proposed system is effective in achieving high levels of agreement with the expert, that (ii) even a simple statistical approach is able to extracting useful information from expert knowledge gained in past cases to further improve performance and finally that (iii) the main difficulty in live deployment concerns the automated selection of the anomaly detection algorithm and the tuning of its hyper-parameters.},
  doi = {},
  note = {bestpaperaward},
  arxiv = {https://arxiv.org/pdf/2107.11078.pdf},
  topic = {ad-fs},
}

@inproceedings{DR:SIGCOMM-20,
  author = {Massimo Gallo and Alessandro Finamore and Gwendal Simon and Dario Rossi},
  title = {Real-time Deep Learning based Traffic Analytics},
  booktitle = {ACM SIGCOMM, Demo session},
  month = {Aug.},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {The increased interest towards Deep Learning (DL) tech-nologies has led to the development of a new generation of specialized hardware accelerator such as Graphic Processing Unit (GPU) and Tensor Processing Unit (TPU). The integration of such components in network routers is however not trivial. Indeed, routers typically aim to minimize the overhead of per-packet processing, and design choices to integrate a new accelerator need to factor in these key requirements. The literature and benchmarks on DL hardware accelerators have overlooked specific router constraints (e.g., strict latency) and focused instead on cloud deployment and image processing. Likewise,there is limited literature regarding DL application on traffic processing at line-rate. Among all hardware accelerators, we are interested in edge TPUs. Since their design focuses on DL inference, edge TPUs matches the vision of operators, who consider running pre-trained DL models in routers with low power drain. Edge TPUs are expected to limit the amount of computational resources for inference and to yield a higher ratio of operations-per-watt footprint than GPUs.This demo aims to investigate the operational points at which edge TPUs become a viable option, using traffic classification as a use case. We sketch the design of a real-time DL traffic classification system, and compare inference speed (i.e., number of classifications per second) of a state-of-the-art Convolutional Neural Network (CNN) model running on different hardware (CPU, GPU, TPU). To constrast their performance, we run stress tests based on synthetic traffic and under different conditions. We collect the results into a dashboard which enables network operators and system designers to both explore the stress test results with regards to their considered operational points, as well as triggering synthetic live tests on top of Ascend310 TPUs.},
  doi = {},
  howpublished = {https://dl.acm.org/doi/10.1145/3405837.3411398},
  topic = {tc-system},
}

@inproceedings{DR:INFOCOM-20a,
  author = {Jose Manuel Navarro and Dario Rossi},
  title = {HURRA: Human-Readable Router Anomaly Detection},
  booktitle = {IEEE INFOCOM, Demo session},
  month = {july},
  year = {2020},
  abstract = {Automated troubleshooting tools must be based on solid and principled algorithms to be useful. However, these tools need to be easily accessible for non-experts, thus requiring to also be usable. This demo combines both requirements by combining an anomaly detection engine inspired by Auto-ML principles, that combines multiple methods to find robust solutions, with automated ranking of results to provide an intuitive interface that is remindful of a search engine. The net result is that HURRA! simplifies as much as possible human operators interaction while providing them with the most useful results first. In the demo, we contrast manual labeling of individual features gathered from human operators from real troubleshooting tickets with results returned by the engine --- showing an empirically good match at a fraction of the human labor.},
  volume = {},
  pages = {},
  doi = {},
  howpublished = {https://ieeexplore.ieee.org/document/9163024},
  topic = {ad-fs},
}

@inproceedings{DR:INFOCOM-20b,
  author = {Cedric Beliard and Alessandro Finamore and Dario Rossi},
  title = {Opening the Deep Pandora Box: Explainable Traffic Classification},
  booktitle = {IEEE INFOCOM, Demo session},
  month = {july},
  year = {2020},
  abstract = {Fostered by the tremendous success in the image recognition field, recently there has been a strong push for the adoption of Convolutional Neural Networks (CNN) in networks, especially at the edge, assisted by low-power hardware equipment (known as “tensor processing units”) for the acceleration of CNN- related computations. The availability of such hardware has reignited the interest for traffic classification approaches that are based on Deep Learning. However, unlike tree-based approaches that are easy to interpret, CNNs are in essence represented by a large number of weights, whose interpretation is particularly obscure for the human operators. Since human operators will need to deal, troubleshoot, and maintain these automatically learned models, that will replace the more easily human-readable heuristic rules of DPI classification engine, there is a clear need to open the “deep pandora box”, and make it easily accessible for network domain experts. In this demonstration, we shed light in the inference process of a commercial-grade classification engine dealing with hundreds of classes, enriching the classification workflow with tools to enable better understanding of the inner mechanics of both the traffic and the models.},
  volume = {},
  pages = {},
  doi = {},
  howpublished = {https://ieeexplore.ieee.org/document/9162704},
  topic = {tc-xai},
}

@inproceedings{DR:INFOCOM-20c,
  author = {German Sviridov and Cedric Beliard and Gwendal Simon and Andrea Bianco and Paolo Giaccone and Dario Rossi},
  title = {Leveraging AI players for QoE estimation in cloud gaming},
  booktitle = {IEEE INFOCOM, Demo session},
  month = {july},
  year = {2020},
  abstract = {Quality of Experience (QoE) assessment in video games is notorious for its burdensomeness. Employing human subjects to understand network impact on the perceived gaming QoE presents major drawbacks in terms of resources requirement, results interpretability and poor transferability across different games. To overcome these shortcomings, we propose to substitute human players with artificial agents trained with state-of-the-art Deep Reinforcement Learning techniques. Equivalently to traditional QoE assessment, we measure the in-game score achieved by an artificial agent for the game of Doom for varying network parameters. Our results show that the proposed methodology can be applied to understand fine-grained impact of network conditions on gaming experience while opening a lot of new opportunities for network operators and game developers.},
  volume = {},
  pages = {},
  doi = {},
  howpublished = {https://ieeexplore.ieee.org/document/9162732},
  topic = {game-qoe},
}

@inproceedings{DR:INFOCOM-20d,
  title = {Removing human players from the loop: AI-assisted assessment of Gaming QoE},
  author = {German Sviridov, Cedric Beliard, Andrea Bianco, Paolo Giaccone, Dario Rossi},
  booktitle = {IEEE INFOCOM, Workshop on Network Intelligence},
  month = {july},
  year = {2020},
  abstract = {Quality of Experience (QoE) assessment for video games is known for being a heavy-weight process, typically requiring the active involvement of several human players and bringing limited transferability across games. Clearly, to some extent, QoE is correlated with the achieved in-game score, as player frustration will arise whenever realized performance is far from what is expected due to conditions beyond player control such as network congestion in the increasingly prevalent case of networked games. To disrupt the status quo, we propose to remove human players from the loop and instead exploit Deep Reinforcement Learning (DRL) agents to play games under varying network conditions. We apply our framework to a set of Atari games with different types of interaction, showing that the score degradation observed with DRL agents can be exploited in networking devices (e.g., by prioritizing scheduling decisions), reinforcing fairness across games, and thus enhancing the overall quality of gaming experience},
  howpublished = {https://ieeexplore.ieee.org/document/9162916},
  topic = {game-qoe},
}

@article{DR:TNSM-20a,
  author = {F. {Salutari} and D. {Da Hora} and G. {Dubuc} and D. {Rossi}},
  journal = {IEEE Transactions on Network and Service Management},
  title = {Analyzing Wikipedia Users’ Perceived Quality Of Experience: A Large-Scale Study},
  year = {2020},
  month = {June},
  volume = {17},
  number = {2},
  abstract = {The Web is one of the most successful Internet applications. Yet, the quality of Web users’ experience is still largely impenetrable. Whereas Web performance is typically studied with controlled experiments, in this work we perform a large-scale study of a real site, Wikipedia, explicitly asking (a small fraction of its) users for feedback on the browsing experience. The analysis of the collected feedback reveals that 85% of users are satisfied, along with both expected (e.g., the impact of browser and network connectivity) and surprising findings (e.g., absence of day/night, weekday/weekend seasonality) that we detail in this paper. Also, we leverage user responses to build supervised data-driven models to predict user satisfaction which, despite including state-of-the art quality of experience metrics, are still far from achieving accurate results (0.62 recall of negative answers). Finally, we make our dataset publicly available, hopefully contributing in enriching and refining the scientific community knowledge on Web users’ QoE.},
  pages = {1082--1095},
  doi = {10.1109/TNSM.2020.2978685},
  howpublished = {https://ieeexplore.ieee.org/abstract/document/9025257},
  topic = {web-qoe},
}

@inproceedings{DR:NETWORKING-20,
  title = {Revealing QoE of Web Users from Encrypted Network Traffic},
  author = {Alexis Huet and Antoine Saverimoutou and Zied Ben Houidi and Hao Shi, Shengming Cai and Jinchun Xu and Bertrand Mathieu and Dario Rossi},
  year = {2020},
  booktitle = {IFIP Networking},
  venue = {Paris},
  month = {June},
  abstract = {Internet Service Providers (ISPs) have a lot to gain from estimating the Web browsing quality of their customers. However, unlike Content Providers (CPs) who can easily access in-browser computed application-level metrics to estimate Web browsing quality, ISPs come short mainly because of traffic encryption. In this paper, we use exact methods and machine learning to estimate well-known application-level Web browsing QoS metrics (such as SpeedIndex and Page Load Time) from raw encrypted streams of network traffic. Particularly, we present and open-source a unique dataset targeting a large set of popular pages (Alexa top-500), from probes from several ISPs networks, browsers software (Chrome, Firefox) and viewport combinations, for over 200,000 experiments. Our results show our models to be accurate, and we particularly focus on their ability to generalize to previously unseen conditions, giving guidance concerning their retraining},
  howpublished = {https://ieeexplore.ieee.org/document/9142810},
  topic = {web-qoe},
}

@inproceedings{DR:MedComNet-20,
  author = {Flavia Salutari and Matteo Varvello and Renata Teixeira and Vassilis Christophides and Dario Rossi and Diego Da Hora},
  title = {Implications of User Perceived Page Load Time Multi-Modality on Web QoE Measurement},
  booktitle = {MedComNet},
  month = {June},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {Web browsing is one of the most popular applications for both desktop and mobile users. A lot of effort has been devoted to speedup the Web, as well as in designing metrics that can accurately tell whether a webpage loaded fast or not. An often implicit assumption made by industrial and academic research communities is that a single metric is sufficient to assess whether a webpage loaded fast. In this paper we collect and make publicly available a unique dataset which contains webpage features (eg number and type of embedded objects) along with both objective and subjective Web quality metrics. This dataset was collected by crawling over 100 websites--representative of the top 1,000,000 websites in the Web --- while crowdsourcing 6,000 user opinions on user perceived page load time (uPLT). We show that the uPLT distribution is often multi-modal and that, in practice, no more than three modes are present. The main conclusion drawn from our analysis is that, for complex webpages, each of the different objective QoE metrics proposed in the literature (such as AFT, TTI, PLT, etc.) is suited to approximate one of the different uPLT modes.},
  doi = {},
  howpublished = {https://ieeexplore.ieee.org/document/9191615},
  topic = {web-qoe},
}

@misc{DR:PATENT-PCT/EP2020/061440,
  author = {Lixuan Yang and Cedric Beliard and Dario Rossi},
  title = {Devices, Methods, And System For Heterogeneous Data- Adaptive Federated Learning},
  month = {April},
  year = {2020},
  howpublished = {},
}

@misc{DR:PATENT-PCT/EP2020/052332,
  author = {Jose Manuel Navarro and Dario Rossi},
  title = {Device For Monitoring A Computer Network System},
  month = {January},
  year = {2020},
  howpublished = {},
}

@misc{DR:PATENT-PCT/EP2020/050319,
  author = {Alexis Huet and Dario Rossi},
  title = {Devices And Methods For Web Quality Evaluation},
  month = {January},
  year = {2020},
  howpublished = {},
}
 

@inproceedings{DR:IJCAIFL-20,
  author = {Lixuan Yang and Cedric Beliard and Dario Rossi},
  title = {Heterogeneous Data-Aware Federated Learning},
  booktitle = {International Joint Conference on Artificial Intelligence (IJCAI), Workshop on Federated Learning},
  month = {September (deferred to Covid)},
  year = {2020},
  volume = {},
  pages = {},
  abstract = {Federated learning (FL) is an appealing concept to perform distributed training of Neural Networks (NN) while keeping data private. With the industrialization of the FL framework, we identify several problems hampering its successful deployment, such as presence of non i.i.d data, disjoint classes, signal multi-modality across datasets. In this work, we address these problems by proposing a novel method that not only (1) aggregates generic model parameters (e.g. a common set of task generic NN layers) on server (e.g. in traditional FL), but also (2) keeps a set of parameters (e.g, a set of task specific NN layer) specific to each client. We validate our method on the traditionally used public benchmarks (e.g., Femnist) as well as on our proprietary collected dataset (i.e., traffic classification). Results show the benefit of our method, with significant advantage on extreme cases.},
  doi = {},
  arxiv= {https://arxiv.org/abs/2011.06393},
  topic = {tc-train},
}

 

