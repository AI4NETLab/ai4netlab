@inproceedings{DR:CoNEXT-NNI-22a,
  title = {{On Using Pretext Tasks to Learn Representations from Network Logs}},
  author = {Matteo Boffa and Luca Vassio and Idilio Drago and Marco Mellia and Giulia Milan and Zied Ben Houidi and Dario Rossi},
  year = {2022},
  month = {dec},
  abstract = {Learning meaningful representations from network data is critical to ease the adoption of AI as a cornerstone to process network logs. Since a large portion of such data is textual, Natural Language Processing (NLP) appears as an obvious candidate to learn their representations. Indeed, the literature proposes impressive applications of NLP applied to textual network data. However, in the absence of labels, objectively evaluating the goodness of the learned representations is still an open problem. We call for a systematic adoption of domain-specific pretext tasks to select the best representation from network data. Relying on such tasks enables us to evaluate different representations on side machine learning problems and, ultimately, unveiling the best candidate representations for the more interesting downstream tasks for which labels are scarce or unavailable. We apply pretext tasks in the analysis of logs collected from SSH honeypots. Here, a cumbersome downstream task is to cluster events that exhibit a similar attack pattern. We propose the following pipeline: first, we represent the input data using a classic NLP-based approach. Then, we design pretext tasks to objectively evaluate the representation goodness and to select the best one. Finally, we use the best representation to solve the unsupervised task, which uncovers interesting behaviours and attack patterns. All in all, our proposal can be generalized to other text-based network logs beyond honeypots.},
  topic = {network-security},
  booktitle = {ACM CoNext workshop on Native Network Intelligence (NNI)},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3565009.3569522},
}

@inproceedings{DR:CoNEXT-NNI-22b,
  title = {{Native Network Intelligence, Fast and Slow}},
  author = {Dario Rossi and Zhang Liang},
  abstract = {As networks have historically been built around connectivity, architectural features concerning quality of service, mobility, security and privacy have been added as afterthoughts -- with consequent well known architectural headaches for their later integration. Despite Artificial Intelligence (AI) is more a means to an end, that an architectural feature itself, this is not completely different from what concerns its integration: in particular, while Cloud and Edge computing paradigms made it possible to use AI techniques to relieve part of network operation, however AI is currently little more than an additional tool. This paper describes a vision of future networks, where AI becomes a first class commodity: its founding principle lays around the concept of ``fast and slow'' type of AI reasoning, each of which offers different types of AI capabilities to process network data. We next outline how these building blocks naturally maps to different network segments, and discuss emerging AI-to-AI communication patterns as we move to more intelligent networks.},
  year = {2022},
  month = {dec},
  topic = {ai-native},
  booktitle = {ACM CoNext workshop on Native Network Intelligence (NNI)},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3565009.3569521},
}

@inproceedings{DR:CoNEXT-GNN-22,
  title = {{Cross-network transferable neural models for WLAN interference estimation}},
  author = {Danilo Marinho Fernandes and Jonatan Krolikowski and Zied Ben Houidi and Fuxing Chen and Dario Rossi},
  year = {2022},
  month = {dec},
  booktitle = {ACM CoNext workshop on Graph Neural Networks (GNN)},
  topic = {wlan},
  abstract = {Airtime interference is a key performance indicator for WLANs, measuring, for a given time period, the percentage of time during which a node is forced to wait for other transmissions before to transmitting or receiving. Being able to accurately estimate interference resulting from a given state change (e.g., channel, bandwidth, power) would allow a better control of WLAN resources, assessing the impact of a given configuration before actually implementing it. In this paper, we adopt a principled approach to interference estimation in WLANs. We first use real data to characterize the factors that impact it, and derive a set of relevant synthetic workloads for a controlled comparison of various deep learning architectures in terms of accuracy, generalization and robustness to outlier data. We find, unsurprisingly, that Graph Convolutional Networks (GCNs) yield the best performance overall, leveraging the graph structure inherent to campus WLANs. We notice that, unlike e.g. LSTMs, they struggle to learn the behavior of specific nodes, unless given the node indexes in addition. We finally verify GCN model generalization capabilities, by applying trained models on operational deployments unseen at training time.},
  howpublished = {https://dl.acm.org/doi/10.1145/3565473.3569184},
}

@inproceedings{DR:AICCSA-22,
  title = {{StreamRHF: Tree-based unsupervised anomaly detection for data streams}},
  author = {Stefan Nesic and Andrian Putina and Maroua Bahri and Alexis Huet and Jose Manuel Navarro and Dario Rossi and Mauro Sozio},
  year = {2022},
  month = {dec},
  booktitle = {19th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA 2022)},
  abstract = {We present StreamRHF, an unsupervised anomaly detection algorithm for data streams. Our algorithm builds on some of the ideas of Random Histogram Forest (RHF), a state-of-the-art algorithm for batch unsupervised anomaly detection. StreamRHF constructs a forest of decision trees, where feature splits are determined according to the kurtosis score of every feature. It irrevocably assigns an anomaly score to data points, as soon as they arrive, by means of an incremental computation of its random trees and the kurtosis scores of the features. This allows efficient online scoring and concept drift detection altogether. Our approach is tree-based which boasts several appealing properties, such as explainability of the results. We conduct an extensive experimental evaluation on multiple datasets from different real-world applications. Our evaluation shows that our streaming algorithm achieves comparable average precision to RHF while outperforming state-of-the-art streaming approaches for unsupervised anomaly detection with furthermore limited computational complexity.},
  howpublished = {https://www.computer.org/csdl/proceedings-article/aiccsa/2022/10017876/1KJxuvEdL4k},
  topic = {ad-algo},
}

 

@techreport{DR:ComNet-22,
  title = {Human readable network troubleshooting based on anomaly detection and feature scoring},
  author = {Jose Manuel Navarro and Alexis Huet and Dario Rossi},
  journal = {Elsevier Computer Networks},
  month = {Nov},
  volume = {219},
  year = {2022},
  issn = {1389-1286},
  abstract = {Network troubleshooting is still a heavily human-intensive process. To reduce the time spent by human operators in the diagnosis process, we present a system based on (i) unsupervised learning methods for detecting anomalies in the time domain, (ii) an attention mechanism to rank features in the feature space and finally (iii) an expert knowledge module able to seamlessly incorporate previously collected domain-knowledge. In this paper, we thoroughly evaluate the performance of the full system and of its individual building blocks: particularly, we consider (i) 10 anomaly detection algorithms as well as (ii) 10 attention mechanisms, that comprehensively represent the current state of the art in the respective fields. Leveraging a unique collection of expert-labeled datasets worth several months of real router telemetry data, we perform a thorough performance evaluation contrasting practical results in constrained stream-mode settings, with the results achievable by an ideal oracle in academic settings. Our experimental evaluation shows that (i) the proposed system is effective in achieving high levels of agreement with the expert, and (ii) that even a simple statistical approach is able to extract useful information from expert knowledge gained in past cases, significantly improving troubleshooting performance.},
  topic = {ad-fs},
  doi = {https://doi.org/10.1016/j.comnet.2022.109447},
  arxiv = {https://arxiv.org/abs/2108.11807},
  howpublished = {https://www.sciencedirect.com/science/article/abs/pii/S1389128622004819},
}

@inproceedings{DR:HotNets-22,
  title = {{Towards a systematic multi-modal representation learning for network data}},
  author = {Zied Ben Houidi and Raphael Azorin and Massimo Gallo and Alessandro Finamore and Dario Rossi},
  abstract = {Learning the right representations from complex input data is the key ability of successful machine learning (ML) models. The latter are often tailored to a specific data modality. For example, recurrent neural networks (RNNs) were designed having the processing of sequential data in mind, while convolutional neural networks (CNNs) were designed to exploit spatial correlation naturally present in images. Unlike computer vision (CV) and natural language processing (NLP), each of which targets a single well-defined modality, network ML problems often have a mixture of data modalities as input. Yet, instead of exploiting such abundance, practitioners tend to rely on sub-features thereof, reducing the problem on single modality for the sake of simplicity. In this paper, we advocate for exploiting all the modalities naturally present in network data. As a first step, we observe that network data systematically exhibits a mixture of quantities (e.g., measurements), and entities (e.g., IP addresses, names, etc.). Whereas the former are generally well exploited, the latter are often underused or poorly represented (e.g., with one-hot encoding). We propose to systematically leverage state of the art embedding techniques to learn entity representations, whenever significant sequences of such entities are historically observed. Through two diverse usecases, we show that such entity encoding can benefit and naturally augment classic quantity-based features.},
  year = {2022},
  month = {nov},
  booktitle = {ACM HotNets},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3563766.3564108},
  topic = {ai-native},
}

@article{DR:TNSM-22,
  title = {Landing AI on Networks: An equipment vendor viewpoint on Autonomous Driving Networks},
  author = {Dario Rossi and Liang Zhang},
  month = {sep},
  volume = {19},
  issue = {3},
  year = {2022},
  journal = {IEEE Transactions on Network and Service Management (TNSM)},
  abstract = {The tremendous achievements of Artificial Intelligence (AI) in computer vision, natural language processing, games and robotics, has extended the reach of the AI hype to other fields: in telecommunication networks, the long term vision is to let AI fully manage, and autonomously drive, all aspects of network operation. In this industry vision paper, we discuss challenges and opportunities of Autonomous Driving Network (ADN) driven by AI technologies. To understand how AI can be successfully landed in current and future networks, we start by outlining challenges that are specific to the networking domain, putting them in perspective with advances that AI has achieved in other fields. We then present a system view, clarifying how AI can be fitted in the network architecture. We finally discuss current achievements as well as future promises of AI in networks, mentioning roadmap to avoid bumps in the road that leads to true large-scale deployment of AI technologies in network},
  doi = {10.1109/TNSM.2022.3169988},
  howpublished = {https://ieeexplore.ieee.org/document/9762358},
  arxiv = {https://arxiv.org/abs/2205.08347},
  topic = {ai-native},
}

@inproceedings{DR:ITC-22,
  title = {Rare Yet Popular: Evidence and Implications from Anomaly Detection Datasets},
  author = {Jose Manuel Navarro and Alexis Huet and Dario Rossi},
  month = {sep},
  year = {2022},
  booktitle = {International Teletraffic Congress (ITC34)},
  abstract = {Anomaly detection research works generally propose algorithms or end-to-end systems that are designed to automatically discover outliers in a dataset or a stream. While literature abounds concerning algorithms or the definition of metrics for better evaluation, the quality of the ground truth against which they are evaluated is seldom questioned. On this paper, we present a systematic analysis of available public (and additionally our private) ground truth for anomaly detection in the context of network environment, where data is intrinsically temporal, multivariate and, in particular, exhibits spatial properties, which to the best of our knowledge we are the first to explore. Our analysis reveals that, while anomalies are by definition temporally rare events, their spatial characterization clearly shows some type of anomalies are significantly more popular than others. This can be achieved through surprisingly simple techniques and may have profound implications on the cost and quality of the labeling process.},
  arxiv = {https://arxiv.org/abs/2211.10129},
  topic = {ad-fs},
}

@article{DR:ComCom-22,
  title = {Neural language models for network configuration: Opportunities and reality check},
  author = {Zied Ben Houidi and Dario Rossi},
  month = {Sep},
  issue = {193},
  pages = {Pages 118-125},
  year = {2022},
  journal = {Elsevier Computer Communication},
  abstract = {Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (e.g. word2vec) as well as novel architectures (e.g. transformers).This success quickly invited researchers to explore the use of NLP techniques to other field, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code synthesis, code repair, cross language translation etc.). By extension, NLP has potential for application to network configuration languages as well, for instance considering tasks such as network configuration verification, synthesis, and cross-vendor translation. In this paper, we survey recent advances in deep learning applied to programming languages, for the purpose of code verification, synthesis and translation: in particularly, we review their training requirements and expected performance, and qualitatively assess whether similar techniques can benefit corresponding use-cases in networking.},
  howpublished = {https://www.sciencedirect.com/science/article/abs/pii/S0140366422002377},
  doi = {https://doi.org/10.1016/j.comcom.2022.06.035},
  arxiv = {https://arxiv.org/abs/2205.01398},
  topic = {ai-native},
}

@article{DR:SIGMETRICS-PEVA-22,
  author = {Roberts, James and Rossi, Dario},
  title = {Size-Based Scheduling vs Fairness for Datacenter Flows: A Queuing Perspective},
  year = {2022},
  month = {Sep},
  volume = {50},
  number = {2},
  url = {https://doi.org/10.1145/3561074.3561076},
  arxiv = {https://arxiv.org/abs/2203.12983},
  abstract = {Contrary to the conclusions of a recent body of work where approximate shortest remaining processing time first (SRPT) flow scheduling is advocated for datacenter networks, this paper aims to demonstrate that imposing fairness remains a preferable objective. We evaluate abstract queuing models by analysis and simulation to illustrate the non-optimality of SRPT under the reasonable assumptions that datacenter source-destination flows occur in batches and bursts and not, as usually assumed, individually at the instants of a Poisson process. Results for these models have significant implications for the design of bandwidth sharing strategies for datacenter networks. In particular, we propose a novel "virtual fair scheduling" algorithm that enforces fairness between batches and is arguably simple enough to be implemented in high speed devices.},
  journal = {ACM SIGMETRICS Perform. Eval. Rev.},
  howpublished = {https://dl.acm.org/doi/10.1145/3561074.3561076},
  topic = {performance},
}

@misc{DR:PATENT-PCT/EP2022/075646,
  author = {Lixuan YANG and Alessandro FINAMORE and Fuxing CHEN and Dario ROSSI},
  title = {A device and method for network traffic classification},
  month = {September},
  year = {2022},
  howpublished = {},
}

@inproceedings{DR:KDD-22,
  title = {Local Evaluation of Time Series Anomaly Detection Algorithms},
  author = {Alexis Huet and Jose Manuel Navarro and Dario Rossi},
  year = {2022},
  month = {aug},
  booktitle = {ACM SIGKDD Conference on Knowledge Discovery and Data mining (KDD)},
  abstract = {In recent years, specific evaluation metrics for time series anomaly detection algorithms have been developed to handle the limitations of the classical precision and recall. However, such metrics are heuristically built as an aggregate of multiple desirable aspects, introduce parameters and wipe out the interpretability of the output. In this article, we first highlight the limitations of the classical precision/recall, as well as the main issues of the recent event-based metrics -- for instance, we show that an adversary algorithm can reach high precision and recall on almost any dataset under weak assumption. To cope with the above problems, we propose a theoretically grounded, robust, parameter-free and interpretable extension to precision/recall metrics, based on the concept of ``affiliation'' between the ground truth and the prediction sets. Our metrics leverage measures of duration between ground truth and predictions, and have thus an intuitive interpretation. By further comparison against random sampling, we obtain a normalized precision/recall, quantifying how much a given set of results is better than a random baseline prediction. By construction, our approach keeps the evaluation local regarding ground truth events, enabling fine-grained visualization and interpretation of algorithmic results. We compare our proposal against various public time series anomaly detection datasets, algorithms and metrics. We further derive theoretical properties of the affiliation metrics that give explicit expectations about their behavior and ensure robustness against adversary strategies.},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3534678.3539339},
  arxiv = {https://arxiv.org/abs/2206.13167},
  topic = {ad-algo},
}

@article{DR:SIGCOMM-CCR-22,
  title = {{AppClassNet: A commercial-grade dataset for application identification research}},
  author = {Chao Wang and Alessandro Finamore and Lixuan Yang and Kevin Fauvel and Dario Rossi},
  year = {2022},
  journal = {ACM SIGCOMM Computer Communication Review},
  month = {july},
  volume = {52},
  issue = {3},
  abstract = {The recent success of Artificial Intelligence (AI) is rooted into several concomitant factors, namely theoretical progress coupled with abundance of data and computing power. Large companies can take advantage of a deluge of data, typically withhold from the research community due to privacy or business sensitivity concerns, and this is particularly true for networking data. Therefore, the lack of high quality data is often recognized as one of the main factors currently limiting networking research from fully leveraging AI methodologies potential. Following numerous requests we received from the scientific community, we release AppClassNet, a commercial-grade dataset for benchmarking traffic classification and management methodologies. AppClassNet is significantly larger than the datasets generally available to the academic community in terms of both the number of samples and classes, and reaches scales similar to the popular ImageNet dataset commonly used in computer vision literature. To avoid leaking user- and business-sensitive information, we opportunely anonymized the dataset, while empirically showing that it still represents a relevant benchmark for algorithmic research. In this paper, we describe the public dataset and our anonymization process. We hope that AppClassNet can be instrumental for other researchers to address more complex commercial-grade problems in the broad field of traffic classification and management.},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3561954.3561958},
  dataseturl={https://figshare.com/articles/dataset/AppClassNet_-_A_commercial-grade_dataset_for_application_identification_research/20375580},
  doi = {https://doi.org/10.1145/3561954.3561958},
  topic = {tc-train},
}
  
@inproceedings{DR:INFOCOM-22,
  title = {Accelerating Deep Learning Classification with Error-controlled Approximate-key Caching},
  author = {Alessandro Finamore and James Roberts and Massimo Gallo and Dario Rossi},
  abstract = {While Deep Learning (DL) technologies are a promising tool to solve networking problems that map to classification tasks, their computational complexity is still too high with respect to real-time traffic measurements requirements. To reduce the DL inference cost, we propose a novel caching paradigm, that we named approximate-key caching, which returns approximate results for lookups of selected input based on cached DL inference results. While approximate cache hits alleviate DL inference workload and increase the system throughput, they however introduce an approximation error. As such, we couple approximate-key caching with an error-correction principled algorithm, that we named auto-refresh. We analytically model our caching system performance for classic LRU and ideal caches, we perform a trace-driven evaluation of the expected performance, and we compare the benefits of our proposed approach with the state-of-the-art similarity caching -- testifying the practical interest of our proposal.},
  booktitle = {IEEE INFOCOM},
  year = {2022},
  month = {may},
  arxiv = {https://arxiv.org/abs/2112.06671},
  howpublished = {https://dl.acm.org/doi/10.1109/INFOCOM48880.2022.9796677},
  topic = {tc-system},
}

@misc{DR:PATENT-PCT/EP2022/059292,
  author = {Alessandro FINAMORE and Lixuan YANG and Dario ROSSI},
  title = {Method to address extreme class imbalance in AI based classifiers},
  month = {April},
  year = {2022},
  howpublished = {},
}

@misc{DR:PATENT-PCT/EP2022/057757,
  author = {Jose Manuel NAVARRO and Alexis HUET and Dario ROSSI},
  title = {Aggregation of Anomalies in a Network},
  month = {March},
  year = {2022},
  howpublished = {},
}

@misc{DR:PATENT-PCT/EP2022/051624,
  author = {Zied BEN HOUIDI and Jonatan KROLIKOWSKI and Dario ROSSI},
  title = {Network resource control based on neighborhood measurements},
  month = {January},
  year = {2022},
  howpublished = {},
}

@inproceedings{DR:AAAI-22,
  title = {Neural combinatorial optimization beyond the TSP: Existing architectures under-represent graph structure},
  author = {Matteo Boffa and Zied Ben Houidi and Jonatan Krolikowski and Dario Rossi},
  year = {2022},
  booktitle = {AAAI workshop on Graphs and more complex structures for learning and reasoning (GLCR'22)},
  abstract = {Recent years have witnessed the promise that reinforcement learning, coupled with Graph Neural Network (GNN) architectures, could learn to solve hard combinatorial optimization problems: given raw input data and an evaluator to guide the process, the idea is to automatically learn a policy able to return feasible and high-quality outputs. Recent work have shown promising results but the latter were mainly evaluated on the travelling salesman problem (TSP) and similar abstract variants such as Split Delivery Vehicle Routing Problem (SDVRP). This paper assesses how and whether recent neural architectures also transfer to graph problems of practical interest. We thus set out to systematically transfer these architectures to the Power and Channel Allocation Problem (PCAP), which has practical relevance for, e.g., radio resource allocation in wireless networks. Our experimental results suggest that existing architectures (i) are still incapable of capturing graph structural features and (ii) are not suitable for problems where the actions on the graph change the graph attributes. On a positive note, we show that augmenting the structural representation of problems with Distance Encoding is a promising step towards the still-ambitious goal of learning multi-purpose autonomous solvers.},
  arxiv = {https://arxiv.org/abs/2201.00668},
  topic = {wlan},
}

