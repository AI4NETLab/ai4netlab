@inproceedings{PAM-24,
  title = {{Data Augmentation for Traffic Classification}},
  author = {Wang, Chao and Finamore, Alessandro and Pietro, Michiardi and Gallo, Massimo and Rossi, Dario},
  year = {2024},
  booktitle = {Passive and Active Measurements (PAM)},
  note = {bestpaperrunnerup},
  arxiv={https://arxiv.org/abs/2401.10754},
  howpublished={https://arxiv.org/abs/2401.10754},
}

@article{CoNEXT-24,
author = {Azorin, Raphael and Monterubbiano, Andrea and Castellano, Gabriele and Gallo, Massimo and Pontarelli, Salvatore and Rossi, Dario},
title = {Taming the Elephants: Affordable Flow Length Prediction in the Data Plane},
year = {2024},
issue_date = {March 2024},
howpublished = {https://doi.org/10.1145/3649473},
doi = {10.1145/3649473},
abstract = {Machine Learning (ML) shows promising potential for enhancing networking tasks by providing early traffic predictions. However, implementing an ML-enabled system is a challenging task due to network devices limited resources. While previous works have shown the feasibility of running simple ML models in the data plane, integrating them into a practical end-to-end system is not an easy task. It requires addressing issues related to resource management and model maintenance to ensure that the performance improvement justifies the system overhead. In this work, we propose DUMBO, a versatile end-to-end system to generate and exploit early flow size predictions at line rate. Our system seamlessly integrates and maintains a simple ML model that offers early coarse-grain flow size prediction in the data plane. We evaluate the proposed system on flow scheduling, per-flow packet inter-arrival time distribution, and flow size estimation using real traffic traces, and perform experiments using an FPGA prototype running on an AMD(R)-Xilinx(R) Alveo U280 SmartNIC. Our results show that DUMBO outperforms traditional state-of-the-art approaches by equipping network devices data planes with a lightweight ML model. Code is available at https://github.com/cpt-harlock/DUMBO.},
journal = {Proc. of CoNEXT'24 (PACMNET).},
articleno = {5},
numpages = {24},
keywords = {data plane, in-network machine learning, per-flow monitoring}
}

@article{COMNET-24,
title = {{MEMENTO: A novel approach for class incremental learning of encrypted traffic}},
journal = {Computer Networks},
pages = {110374},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110374},
howpublished = {https://www.sciencedirect.com/science/article/pii/S1389128624002068},
author = {Francesco Cerasuolo and Alfredo Nascita and Giampaolo Bovenzi and Giuseppe Aceto and Domenico Ciuonzo and Antonio Pescapè and Dario Rossi},
keywords = {Traffic classification, Class incremental learning, Mobile apps, Encrypted traffic, Deep learning},
abstract = {In the ever-changing digital environment, ensuring the ongoing effectiveness of traffic analysis and security measures is crucial. Therefore, Class Incremental Learning (CIL) in encrypted Traffic Classification (TC) is essential for adapting to evolving network behaviors and the rapid development of new applications. However, the application of CIL techniques in the TC domain is not straightforward, usually leading to unsatisfactory performance figures. Specifically, the improvement goal is to reduce forgetting on old apps and increase the capacity in learning new ones, in order to improve overall classification performance— reducing the drop from a model “trained-from-scratch”. The contribution of this work is the design of a novel fine-tuning approach called MEMENTO, which is obtained through the careful design of different building blocks: memory management, model training, and rectification strategies. In detail, we propose the application of traffic biflows augmentation strategies to better capitalize on old apps biflows, we introduce improvements in the distillation stage, and we design a general rectification strategy that includes several existing proposals. To assess our proposal, we leverage two publicly-available encrypted network traffic datasets, i.e., MIRAGE19 and CESNET-TLS22. As a result, on both datasets MEMENTO achieves a significant improvement in classifying new apps (w.r.t. the best-performing alternative, i.e., BiC) while maintaining stable performance on old ones. Equally important, MEMENTO achieves satisfactory overall TC performance, filling the gap toward a trained-from-scratch model and offering a considerable gain in terms of time (up to 10× speed-up) to obtain up-to-date and running classifiers. The experimental evaluation relies on a comprehensive performance evaluation workbench for CIL proposals, which is based on a wider set of metrics (as opposed to the existing literature in TC).}
}
